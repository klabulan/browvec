# Task: Enhanced FTS5 Tokenizer Configuration

**Date:** 2025-10-16
**Status:** Implementation
**Related Commits:** 66ee684 (unicode61 base implementation)

## Problem Statement

### Primary Issue: Russian Search Not Working
Users report that Russian text search fails even after schema v4 (unicode61 tokenizer) implementation.

**Root Cause Analysis:**
1. **Old Database Schema**: Users working with databases created before schema v4 still have ASCII tokenizer
2. **No Auto-Migration**: Schema v4 requires manual database recreation (export ‚Üí clear ‚Üí reimport)
3. **Lack of Fuzzy Matching**: Current unicode61 configuration doesn't handle accent variations (—ë vs –µ)
4. **No Partial Word Search**: Users want to search for "–ü—É—à–∫" and find "–ü—É—à–∫–∏–Ω"

### Secondary Issue: Partial Word Search
Current implementation requires exact word matches. Users want:
- Prefix search: "–ü—É—à–∫*" ‚Üí "–ü—É—à–∫–∏–Ω"
- Fuzzy matching: "—ë" ‚âà "–µ"
- Better autocomplete support

## Solution Design

### Schema Version 5: Enhanced Tokenizer

**Tokenizer Configuration:**
```sql
tokenize='unicode61 remove_diacritics 1'
```

**Benefits:**
- ‚úÖ Full Unicode support (Cyrillic, CJK, Arabic, etc.)
- ‚úÖ Case-insensitive search
- ‚úÖ Diacritic-insensitive: —ë ‚Üí –µ, √° ‚Üí a, √º ‚Üí u
- ‚úÖ Better fuzzy matching for Russian text
- ‚úÖ Compatible with FTS5 prefix operator: `word*`

**Trade-offs:**
- ‚ö†Ô∏è Slightly reduced precision (—ë and –µ treated as equivalent)
- ‚ö†Ô∏è Requires database recreation for existing users

## Implementation

### 1. Schema Version Bump

**File:** `src/database/worker/schema/SchemaManager.ts`

```typescript
// Line 17: Bump version
export const CURRENT_SCHEMA_VERSION = 5;
```

**Documentation:**
```typescript
/**
 * Database schema version
 *
 * Version 4: Added unicode61 tokenizer for Cyrillic/multilingual support
 * Version 5: Enhanced tokenizer with remove_diacritics for fuzzy matching
 */
```

### 2. Enhanced FTS5 Table Creation

**File:** `src/database/worker/schema/SchemaManager.ts`

**Change line 239:**
```typescript
// Before (v4):
tokenize='unicode61'

// After (v5):
tokenize='unicode61 remove_diacritics 1'
```

**Complete DDL:**
```sql
CREATE VIRTUAL TABLE IF NOT EXISTS fts_default USING fts5(
  title, content, metadata,
  content=docs_default,
  content_rowid=rowid,
  tokenize='unicode61 remove_diacritics 1'
);
```

## Testing Strategy

### Test Cases

1. **Basic Russian Search**
   - Query: `–ü—É—à–∫–∏–Ω` ‚Üí Should find documents about Pushkin
   - Query: `–ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–∞` ‚Üí Should find literature documents
   - Query: `–†–æ—Å—Å–∏—è` ‚Üí Should find Russia-related content

2. **Case Insensitivity**
   - Query: `–ø—É—à–∫–∏–Ω` (lowercase) ‚Üí Same results as `–ü—É—à–∫–∏–Ω`
   - Query: `–¢–û–õ–°–¢–û–ô` (uppercase) ‚Üí Same results as `–¢–æ–ª—Å—Ç–æ–π`

3. **Diacritic Insensitivity**
   - Query: `—ë–ª–∫–∞` and `–µ–ª–∫–∞` ‚Üí Both should return same results
   - Query: `–§—ë–¥–æ—Ä` and `–§–µ–¥–æ—Ä` ‚Üí Both should match Dostoevsky

4. **Prefix Search (FTS5 operator)**
   - Query: `–ü—É—à–∫*` ‚Üí Should find "–ü—É—à–∫–∏–Ω", "–ü—É—à–∫–∏–Ω—Å–∫–∏–π"
   - Query: `–¢–æ–ª—Å—Ç*` ‚Üí Should find "–¢–æ–ª—Å—Ç–æ–π", "–¢–æ–ª—Å—Ç–∞—è"

5. **Multi-word Search**
   - Query: `–ü—É—à–∫–∏–Ω –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–∞` ‚Üí Documents containing both
   - Query: `–†–æ—Å—Å–∏—è –∏—Å—Ç–æ—Ä–∏—è` ‚Üí Russian history documents

### Test Execution

**Manual Testing:**
```javascript
// Browser console after loading demo

// 1. Check schema version
const schema = await db.execAsync('SELECT MAX(schema_version) as version FROM collections');
console.log('Schema version:', schema[0].values[0][0]); // Should be 5

// 2. Check tokenizer
const ftsSchema = await db.execAsync("SELECT sql FROM sqlite_master WHERE name='fts_default'");
console.log('FTS5 DDL:', ftsSchema[0].values[0][0]); // Should include remove_diacritics

// 3. Test Russian search
const results = await db.search({ query: { text: '–ü—É—à–∫–∏–Ω' }, limit: 10 });
console.log('Search results:', results.results.length); // Should be > 0

// 4. Test prefix search
const prefixResults = await db.execAsync("SELECT * FROM fts_default WHERE fts_default MATCH '–ü—É—à–∫*'");
console.log('Prefix results:', prefixResults[0].values.length); // Should be > 0
```

**Automated Testing:**
Use the diagnostic script `COMPREHENSIVE_SEARCH_DIAGNOSTIC.js`

## Migration Guide

### For Users with Old Databases

**Option 1: Export ‚Üí Clear ‚Üí Reimport (RECOMMENDED)**
```javascript
// 1. Export existing data
const exported = await db.exportAsync();

// 2. Save to file (or keep in memory)
const blob = new Blob([exported], { type: 'application/x-sqlite3' });
const url = URL.createObjectURL(blob);
const a = document.createElement('a');
a.href = url;
a.download = 'localretrieve-backup.db';
a.click();

// 3. Clear database
await db.clearAsync();

// 4. Reimport
// (Load file via file input, then:)
await db.importAsync(backupData);

// 5. Verify
const schema = await db.execAsync('SELECT MAX(schema_version) as version FROM collections');
console.log('New schema version:', schema[0].values[0][0]); // Should be 5
```

**Option 2: Manual FTS5 Rebuild**
```javascript
// Drop and recreate FTS5 table
await db.execAsync('DROP TABLE fts_default');

await db.execAsync(`
  CREATE VIRTUAL TABLE fts_default USING fts5(
    title, content, metadata,
    content=docs_default,
    content_rowid=rowid,
    tokenize='unicode61 remove_diacritics 1'
  )
`);

// Rebuild index
await db.execAsync(`
  INSERT INTO fts_default(rowid, title, content, metadata)
  SELECT rowid, title, content, metadata FROM docs_default
`);

// Update schema version
await db.execAsync('UPDATE collections SET schema_version = 5, updated_at = strftime("%s", "now")');
```

## Tokenizer Comparison

### unicode61 (Schema v4)
```sql
tokenize='unicode61'
```
- ‚úÖ Handles all Unicode scripts
- ‚úÖ Case-insensitive
- ‚ùå No diacritic folding (—ë ‚â† –µ)
- ‚ùå No partial word search (built-in)
- üí° Use: `word*` for prefix search

### unicode61 + remove_diacritics (Schema v5)
```sql
tokenize='unicode61 remove_diacritics 1'
```
- ‚úÖ Everything from v4
- ‚úÖ Diacritic folding (—ë = –µ, √° = a)
- ‚úÖ Better fuzzy matching
- ‚úÖ More forgiving searches
- ‚ùå May reduce precision in some cases
- üí° Use: `word*` for prefix search

### Trigram (Future Consideration)
```sql
tokenize='trigram'
```
- ‚úÖ True substring search
- ‚úÖ Perfect for autocomplete
- ‚ùå 3-10x larger index
- ‚ùå Slower indexing
- ‚ùå Not suitable for full-text search
- üí° Consider for dedicated autocomplete feature

## Partial Word Search Methods

### Method 1: FTS5 Prefix Operator (RECOMMENDED)
```sql
SELECT * FROM fts_default WHERE fts_default MATCH '–ü—É—à–∫*'
```
- ‚úÖ Works with any tokenizer
- ‚úÖ No index size penalty
- ‚úÖ Fast
- ‚ùå Only prefix matching (not substring)

### Method 2: LIKE Operator (Fallback)
```sql
SELECT * FROM docs_default WHERE title LIKE '%–ü—É—à–∫%' OR content LIKE '%–ü—É—à–∫%'
```
- ‚úÖ True substring search
- ‚úÖ Works always
- ‚ùå Very slow (no index)
- ‚ùå Doesn't use FTS5
- üí° Use only as fallback

### Method 3: Application-Level Tokenization
```javascript
// Split query into tokens, create FTS5 query
const tokens = query.split(/\s+/).map(t => `${t}*`).join(' OR ');
// "–ü—É—à–∫ –¢–æ–ª—Å" ‚Üí "–ü—É—à–∫* OR –¢–æ–ª—Å*"
```
- ‚úÖ User-friendly
- ‚úÖ Leverages FTS5
- ‚úÖ Fast
- üí° RECOMMENDED for production

## Search API Enhancement

### Current API
```javascript
await db.search({ query: { text: '–ü—É—à–∫–∏–Ω' }, limit: 10 });
```

### Enhanced API (Proposal)
```javascript
await db.search({
  query: { text: '–ü—É—à–∫–∏–Ω' },
  limit: 10,
  options: {
    partialMatch: true,      // Auto-append * to tokens
    fuzzyMatch: true,         // Use remove_diacritics
    multiword: 'OR'          // OR vs AND for multi-word queries
  }
});
```

## Performance Considerations

### Index Size Impact
- **v4 (unicode61)**: Baseline
- **v5 (unicode61 + remove_diacritics 1)**: ~+2% index size
- **Trigram**: ~+300-1000% index size

### Query Performance
- **Exact match**: <1ms (same across all)
- **Prefix match (`word*`)**: <5ms (same across all)
- **Substring match (LIKE)**: 10-1000ms (depends on data size)

### Recommendation
**Use schema v5** for the best balance of functionality, performance, and index size.

## Known Issues & Limitations

### Issue 1: No Built-In Substring Search
**Limitation:** FTS5 doesn't support true substring search (e.g., "—à–∫–∏" matching "–ü—É—à–∫–∏–Ω")
**Workaround:** Use prefix operator `*` or implement trigram index for autocomplete

### Issue 2: Manual Schema Migration
**Limitation:** Users must manually export/reimport to upgrade
**Future:** Implement automatic schema migration script

### Issue 3: Precision vs Recall Trade-off
**Limitation:** `remove_diacritics 1` may return false positives
**Example:** "–ª–µ–¥" (ice) might match "–ª—ë–¥" (same meaning but different spelling)
**Assessment:** Acceptable trade-off for better user experience

## Recommendations

### For This Implementation
1. ‚úÖ **Bump schema to v5** with `tokenize='unicode61 remove_diacritics 1'`
2. ‚úÖ **Update documentation** to explain migration
3. ‚úÖ **Create diagnostic tool** (already done: `COMPREHENSIVE_SEARCH_DIAGNOSTIC.js`)
4. ‚úÖ **Add prefix search** to search API (optional enhancement)

### For Future Enhancements
1. üîÆ **Auto-migration script** for seamless schema upgrades
2. üîÆ **Dedicated autocomplete API** with trigram index
3. üîÆ **Search analytics** to track query patterns
4. üîÆ **Query preprocessing** for better UX (auto-prefix, synonym expansion)

## Success Criteria

- ‚úÖ Russian text search works on fresh databases (schema v5)
- ‚úÖ Prefix search works: `–ü—É—à–∫*` finds "–ü—É—à–∫–∏–Ω"
- ‚úÖ Diacritic-insensitive: `—ë–ª–∫–∞` = `–µ–ª–∫–∞`
- ‚úÖ Case-insensitive: `–ü–£–®–ö–ò–ù` = `–ü—É—à–∫–∏–Ω` = `–ø—É—à–∫–∏–Ω`
- ‚úÖ Migration path documented for old databases
- ‚úÖ Performance remains acceptable (<10ms per query)
- ‚úÖ Index size increase is minimal (<5%)

## References

- [SQLite FTS5 Documentation](https://www.sqlite.org/fts5.html)
- [unicode61 Tokenizer](https://www.sqlite.org/fts5.html#unicode61_tokenizer)
- [FTS5 Prefix Queries](https://www.sqlite.org/fts5.html#prefix_queries)
- Commit 66ee684: Initial unicode61 implementation
